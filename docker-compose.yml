# docker-compose.yml

version: '3.8'

services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
    command: ["ollama", "serve"]

  pipeline:
    build:
      context: .
      dockerfile: ./infra/Dockerfile.scraper
    container_name: pipeline
    volumes:
      - ./data:/app/data
      - ./scraper:/app/scraper
      - ./pipeline:/app/pipeline
      - ./requirements.txt:/app/requirements.txt
      - ./rag:/app/rag
    # A bash command to keep the container running for manual use
    command: /bin/bash -c "tail -f /dev/null"

  api:
    build:
      context: .
      dockerfile: ./infra/Dockerfile.api
    container_name: rag_api
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./rag:/app/rag
      - ./requirements.txt:/app/requirements.txt
    depends_on:
      - ollama
    # Ollama needs to be running before the API starts
    command: ["/bin/bash", "-c", "uvicorn rag.api:app --host 0.0.0.0 --port 8000"]
    environment:
      - OLLAMA_HOST=http://ollama:11434

  ui:
    build:
      context: .
      dockerfile: ./infra/Dockerfile.ui
    container_name: rag_ui
    ports:
      - "8501:8501"
    depends_on:
      - api
    command: ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]